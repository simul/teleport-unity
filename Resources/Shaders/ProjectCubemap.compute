
// (c) 2020 Simul.co

#pragma kernel EncodeTagDataIdCS
#pragma kernel EncodeColorCS
#pragma kernel EncodeCubemapFaceCS
#pragma kernel EncodeWebcamCS

#include "Common.cginc"
// Conventional layout
static const int2 FaceOffsets[] = { {0,0},{1,0},{2,0},{0,1},{1,1},{2,1} };
// GL Layout
//static const int2 FaceOffsets[] = { {2,1},{1,1},{0,0},{1,0},{2,0},{0,1} };

Texture2D<float4> InputColorTexture;
TextureCube<float4> InputCubemapTexture;
SamplerState samplerInputCubemapTexture;
RWTexture2D<float4> RWOutputColorTexture;
RWTexture2DArray<float4> RWOutputColorTextureArray;

int2 Offset;
int2 WebcamCubemapSize;
int2 TagDataIdOffset;
int TagDataId;
int Face;
mat4 FaceToWorldMatrix;

// Here. we will encode the id of the video tag data in 4x4 blocks of monochrome colour.
[numthreads(32, 4, 1)]
void EncodeTagDataIdCS(uint2 ThreadID : SV_DispatchThreadID)
{
	uint OutputW, OutputH;
	RWOutputColorTexture.GetDimensions(OutputW, OutputH);

	// We want to encode one 32-bit number with the minimum possible loss.
	// Therefore we will encode it in...
	// Binary.
	uint raw_uint = asuint(TagDataId);

	// We will use the thread x as the bit index.
	uint masked_bits = (raw_uint >> (ThreadID.x / 4))& uint(1);		// 1 or 0
	int2 Pos = TagDataIdOffset + int2(ThreadID);
	RWOutputColorTexture[Pos] = float4(masked_bits.x, masked_bits.x, masked_bits.x, masked_bits.x);
}

[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void EncodeColorCS(uint2 ThreadID : SV_DispatchThreadID)
{
	uint InputW, InputH;
	InputColorTexture.GetDimensions(InputW, InputH);

	if (ThreadID.x >= InputW || ThreadID.y >= InputH)
		return;

	int2 pos = int2(ThreadID);
	int2 ipos = int2(pos.x, InputH - 1 - pos.y);
	float4 SceneColor = InputColorTexture[ipos];
	SceneColor.x = sqrt(SceneColor.x);
	SceneColor.y = sqrt(SceneColor.y);
	SceneColor.z = sqrt(SceneColor.z);

	pos =pos.xy+ Offset+FaceOffsets[Face] * InputW;

	RWOutputColorTexture[pos] = SceneColor;
}

[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void EncodeCubemapFaceCS(uint2 ThreadID : SV_DispatchThreadID)
{
	uint InputW, InputH, numFaces;
	InputCubemapTexture.GetDimensions(InputW, InputH);

	if (ThreadID.x >= InputW || ThreadID.y >= InputH)
		return;

	int2 pos = int2(ThreadID);
	int4 ipos = int4(pos.x, InputH - 1 - pos.y,Face,0);
	// we must convert Face index and pos into a 3D direction, to get around Unity's API limitations.
	float3 dir=float3(float2(ipos.xy)*2.0-float2(1.0,1.0),1.0);
	// A MATRIX TRANSFORMATION, just to extract a pixel value that we should be able to look up directly...
	// use FaceToWorldMatrix.

	float4 SceneColor = InputCubemapTexture.SampleLevel(samplerInputCubemapTexture,normalize(dir),0);
	SceneColor.x = sqrt(SceneColor.x);
	SceneColor.y = sqrt(SceneColor.y);
	SceneColor.z = sqrt(SceneColor.z);

	pos += Offset+FaceOffsets[Face] * InputW;

	RWOutputColorTexture[pos] = SceneColor;
}

[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void EncodeWebcamCS(uint2 ThreadID : SV_DispatchThreadID)
{
	if (ThreadID.x >= WebcamCubemapSize.x || ThreadID.y >= WebcamCubemapSize.y)
		return;

	uint InputW, InputH;
	InputColorTexture.GetDimensions(InputW, InputH);

	int2 div = int2(InputW, InputH) / int2(WebcamCubemapSize.x, WebcamCubemapSize.y);

	int2 ipos = int2(ThreadID.x, InputH - 1 - ThreadID.y) * div;
	float4 color = InputColorTexture[ipos];
	color.x = sqrt(color.x);
	color.y = sqrt(color.y);
	color.z = sqrt(color.z);

	int2 pos = Offset + ThreadID;

	RWOutputColorTexture[pos] = color;
}
